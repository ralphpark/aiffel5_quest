{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. 머신러닝 모델을 제품으로 만들어보자 : MLOps 기초[프로젝트]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-1. 프로젝트: 이제까지 만들었던 모델을 튜닝하고 배포하기!\n",
    "\n",
    "이번 프로젝트는 여러분들이 배운 프로젝트중에서 하나를 뽑아서 하이퍼파라미터 튜닝을 하고 배포하는 미션입니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 하이퍼파라미터 튜닝\n",
    "\n",
    "이제까지 진행했던 프로젝트 하나를 뽑아서(예시 : Seq2Seq, GAN, CIFAR10 딥러닝 모델, VGG 16모델) KerasTuner로 하이퍼파라미터 튜닝을 진행합니다. 튜닝한 하이퍼 파라미터로 학습을 진행하고 모델을 SavedModel 형식으로 저장해주세요.\n",
    "\n",
    "(주의사항)\n",
    "하이퍼 파라미터를 어느정도 범위로 주는지에 따라서 모델 튜닝속도가 달라집니다.\n",
    "학습시간을 고려해서 하이퍼 파라미터 튜닝을 세팅해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 학습 데이터: (50000, 32, 32, 3) 레이블: (50000, 1)\n",
      "학습 데이터: (40000, 32, 32, 3) 레이블: (40000, 1)\n",
      "검증 데이터: (10000, 32, 32, 3) 레이블: (10000, 1)\n",
      "테스트 데이터: (10000, 32, 32, 3) 레이블: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 문제 3-1: cifar10 데이터셋을 로드하고, 훈련 데이터셋에서 20%를 검증 데이터셋으로 분리합니다.\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
    "#20%를 검증 데이터셋으로 분리\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터와 레이블 종류가 몇개인지 출력합니다.\n",
    "print(\"전체 학습 데이터: {} 레이블: {}\".format(x_train_full.shape, y_train_full.shape))\n",
    "print(\"학습 데이터: {} 레이블: {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"검증 데이터: {} 레이블: {}\".format(x_val.shape, y_val.shape))\n",
    "print(\"테스트 데이터: {} 레이블: {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "x_train = x_train / 255.0\n",
    "x_val = x_val / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_val = to_categorical(y_val, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터: (40000, 32, 32, 3) 레이블: (40000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"학습 데이터: {} 레이블: {}\".format(x_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar10의 분류에 해당하는 'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "# 'dog', 'frog', 'horse', 'ship', 'truck'를 class_name으로 정의합니다.\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepTuner(kt.Tuner):\n",
    "    def run_trial(self, trial, X, y, validation_data, **fit_kwargs):\n",
    "        model = self.hypermodel.build(trial.hyperparameters)\n",
    "        model.fit(X, y, batch_size=trial.hyperparameters.Choice(\n",
    "            'batch_size', [16, 32]), **fit_kwargs)\n",
    "\n",
    "\n",
    "        X_val, y_val = validation_data\n",
    "        eval_scores = model.evaluate(X_val, y_val)\n",
    "        return {name: value for name, value in zip(\n",
    "            model.metrics_names,\n",
    "            eval_scores)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Input Layer\n",
    "    model.add(tf.keras.Input(shape=x_train.shape[1:], name='inputs'))\n",
    "    \n",
    "    # Convolutional Layers with MaxPooling, Batch Normalization, and Dropout\n",
    "    for i in range(hp.Int('num_layers', min_value=1, max_value=3)):  # Reduce max layers to 3\n",
    "        model.add(tf.keras.layers.Conv2D(hp.Int(f'units_{i}', min_value=32, max_value=128, step=32),\n",
    "                                         (3,3), activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "    \n",
    "    # Flatten\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    # Dense Layers with Batch Normalization and Dropout\n",
    "    for i in range(hp.Int('n_connections', 1, 3)):\n",
    "        model.add(tf.keras.layers.Dense(hp.Choice(f'n_nodes_{i}', values=[32, 64, 128, 256]), activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax', name='outputs'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 30s]\n",
      "accuracy: 0.3273000121116638\n",
      "\n",
      "Best accuracy So Far: 0.6150000095367432\n",
      "Total elapsed time: 00h 07m 37s\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the tuner with the improved model building function\n",
    "improved_keras_tuner = DeepTuner(\n",
    "    oracle=kt.oracles.BayesianOptimizationOracle(\n",
    "        objective=kt.Objective('accuracy', 'max'),\n",
    "        max_trials=10,\n",
    "        seed=42),\n",
    "    hypermodel=improved_build_model,\n",
    "    overwrite=True,\n",
    "    project_name='improved_keras_tuner'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "improved_keras_tuner.search(x_train, y_train, validation_data=(x_val, y_val), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 30, 30, 128)       3584      \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPooli  (None, 15, 15, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_44 (Ba  (None, 15, 15, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 15, 15, 128)       0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 13, 13, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPooli  (None, 6, 6, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_45 (Ba  (None, 6, 6, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 6, 6, 32)          0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 256)               295168    \n",
      "                                                                 \n",
      " batch_normalization_46 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 339882 (1.30 MB)\n",
      "Trainable params: 339050 (1.29 MB)\n",
      "Non-trainable params: 832 (3.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the best model and its summary\n",
    "best_hps_improved = improved_keras_tuner.get_best_hyperparameters(num_trials=10)[0]\n",
    "improved_model = improved_build_model(best_hps_improved)\n",
    "improved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ralphpark/aiffel5_quest/exploration/Node14.ipynb 셀 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223137322e33302e312e3930222c22706f7274223a32327d/home/ralphpark/aiffel5_quest/exploration/Node14.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m save_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mHOME\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/aiffel5_quest/exploration/aiffel/mlops/node14/model/1\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223137322e33302e312e3930222c22706f7274223a32327d/home/ralphpark/aiffel5_quest/exploration/Node14.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_path)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223137322e33302e312e3930222c22706f7274223a32327d/home/ralphpark/aiffel5_quest/exploration/Node14.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39msave(fname)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "save_path = os.getenv('HOME') + '/aiffel5_quest/exploration/aiffel/mlops/node14/model/1'\n",
    "fname = os.path.join(save_path)\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 배포하기\n",
    "\n",
    "하이퍼파라미터 튜닝을 끝낸 모델을 Docker 혹은 WSL2 환경에서 TFServing을 진행해 모델을 배포하세요! 모델 배포가 성공했다면 해당 코드쉘을 캡쳐해서 이미지를 주피터 노트북에 넣어주세요!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
    "$ sudo apt update\n",
    "$ sudo apt install tensorflow-model-server\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TFLite 모델 만들기\n",
    "\n",
    "여러분들이 만든 모델을 TFLite 모델로 만들어서 저장하고 서명을 확인하는 메소드까지 입력해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = os.getenv('HOME') + '/aiffel5_quest/exploration/aiffel/mlops/node14/model/1'\n",
    "best_model = tf.keras.models.load_model(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_65 (Conv2D)          (None, 30, 30, 102)       2856      \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 28, 28, 42)        38598     \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 26, 26, 67)        25393     \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 24, 24, 37)        22348     \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 22, 22, 52)        17368     \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 25168)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               6443264   \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6552397 (25.00 MB)\n",
      "Trainable params: 6552397 (25.00 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.(추가미션) 박찬성님의 TFX 프로젝트 분석해보기\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/TFX.max-800x600.png)\n",
    "\n",
    "[박찬성님의 TFX 프로젝트]\n",
    "\n",
    "박찬성님의 프로젝트 : semantic-segmentation-ml-pipeline\n",
    "https://github.com/deep-diver/semantic-segmentation-ml-pipeline\n",
    "\n",
    "이번 노드에서 TensorFlow Extended에 대한 컴포넌트 소개를 했지만 각각 컴포넌트가 어떻게 작동하는지 코드를 보지 않았습니다.\n",
    "현재 Machine Learning GDE(Google Developers Expert)이자 Hugging Face Fellow로 활동하고 계신 박찬성님은 전세계적으로 손꼽히는 TFX를 잘 다루는 유저입니다.\n",
    "위에 올린 깃헙주소의 경우 박찬성님께서 진행한 TFX 프로젝트중 하나로 Semantic Segmentation 모델을 사용한 ML 파이프라인 제작 프로젝트입니다.\n",
    "\n",
    "해당 프로젝트를 분석한다면 여러분들께서 TFX에 대한 이해도가 높아져서 TFX의 매력에 빠지게 될거라는 생각이 듭니다!\n",
    "\n",
    "만일 1번부터 3번까지 프로젝트를 다 진행하셨다면 추가미션을 통해 TFX를 이해하는 시간을 가졌으면 좋겠습니다!\n",
    "\n",
    "오늘도 수고하셨습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
