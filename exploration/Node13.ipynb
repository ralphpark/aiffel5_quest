{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. 머신러닝 모델을 제품으로 만들어보자 : MLOps 기초\n",
    "\n",
    "## 13-1. 들어가며\n",
    "안녕하세요!\n",
    "\n",
    "'머신러닝 모델을 제품으로 만들어보자 : MLOps 기초'노드를 학습하러 오신 여러분들 환영합니다!\n",
    "\n",
    "대부분 머신러닝 모델을 공부한다면 데이터를 받아오고 모델을 설계하고 모델 학습을 진행한 다음 모델 평가하는 과정까지만 배웁니다.\n",
    "\n",
    "그런데... 실제 서비스로 진행할 때 머신러닝 공부한 내용 그대로 하면 될까요?\n",
    "\n",
    "실상은 그렇지 않습니다. 머신러닝을 실험실에서 연구하는 것과 실제 서비스로 운영하는 것은 상당히 다릅니다.\n",
    "\n",
    "이번 노드에서는 실제 머신러닝을 서비스로 운영하는 방법론인 MLOps 이론에 대해 공부할 에정입니다.\n",
    "\n",
    "그렇다면 아이스브레이킹 문제를 풀어볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. ChatGPT나 Bard한테 MLOps를 물어봐주세요!\n",
    "\n",
    "A. 물론이죠! MLOps는 \"Machine Learning Operations\"의 줄임말로, 기계 학습 모델을 실제 운영 환경에서 안정적으로 배포하고 모니터링하는 데 중점을 둔 DevOps의 원칙과 방법론을 활용한 방법론입니다. MLOps는 기계 학습 프로젝트의 전체 수명 주기를 관리하는 데 중점을 둡니다.\n",
    "\n",
    "MLOps의 주요 목표는 다음과 같습니다:\n",
    "\n",
    "1. **모델의 안정적인 배포**: 기계 학습 모델을 실제 운영 환경에 안정적으로 배포하는 것.\n",
    "2. **모델의 지속적인 통합 및 배포 (CI/CD)**: 새로운 데이터나 코드 변경 시 자동으로 모델을 테스트, 훈련, 배포하는 프로세스 구축.\n",
    "3. **모델 모니터링**: 운영 환경에서의 모델 성능 모니터링 및 장애 감지.\n",
    "4. **모델의 거버넌스 및 버전 관리**: 다양한 모델 버전 관리 및 사용된 데이터, 하이퍼파라미터 등의 메타데이터 추적.\n",
    "\n",
    "MLOps의 주요 구성 요소 및 실천 사항은 다음과 같습니다:\n",
    "\n",
    "1. **데이터 및 모델 버전 관리**: 데이터 세트, 코드 및 모델의 버전을 관리하여 재현성을 보장합니다.\n",
    "2. **모델 훈련 자동화**: 새로운 데이터가 사용 가능해지면 모델을 자동으로 훈련합니다.\n",
    "3. **모델 테스트**: 새로 훈련된 모델의 성능을 검증하고 이전 버전과 비교합니다.\n",
    "4. **모델 배포 자동화**: 검증된 모델을 운영 환경에 자동으로 배포합니다.\n",
    "5. **모델 모니터링 및 로깅**: 운영 환경에서의 모델 성능과 예측을 모니터링하고 로그를 기록합니다.\n",
    "6. **모델 롤백**: 문제가 발생하면 이전 버전의 모델로 즉시 롤백합니다.\n",
    "\n",
    "MLOps는 기계 학습 프로젝트의 안정성, 재현성 및 유지 관리성을 향상시키는 데 중요한 역할을 합니다. 기계 학습 모델이 실제 운영 환경에서 예상대로 작동하도록 하기 위해 필요한 여러 단계와 절차를 통합하고 자동화하는 것이 중요합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프로젝트는 무엇인가요?\n",
    "\n",
    "이번 노드의 프로젝트는 여러분들이 이제까지 진행했던 딥러닝 모델을 KerasTuner로 하이퍼파라미터 튜닝을 한 뒤에 TFServing으로 API를 만들어내는 것과 tflite파일을 만드는 것이 목표입니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 내용\n",
    "\n",
    "1. 실험실 속 머신러닝 모델\n",
    "- 머신러닝 모델을 실험실에서만 진행했을 때 발생했던 문제에 대해 공부합니다.\n",
    "2. MLOps의 정의와 ML 시스템의 구성요소\n",
    "- MLOps에 대한 정의와 ML 시스템이 어떻게 구성되는지 알아봅니다.\n",
    "3. TFX (TensorFlow Extended) 소개하기\n",
    "- TFX에 대해 간단하게 알아보고 각 모듈이 어떤건지 알아봅니다.\n",
    "4. 모델을 더 완벽하게 만드는 방법 : KerasTuner\n",
    "- KerasTuner를 활용해서 하이퍼 파라미터 튜닝을 합니다.\n",
    "5. 이제는 모델을 배포할 차례! : TFServing & TFLite\n",
    "- TensorFLow Serving과 TFLite로 모델을 배포하는 방법에 대해 알아봅니다.\n",
    "\n",
    "### 학습 목표\n",
    "\n",
    "MLOps 이론에 대한 기초를 알 수 있습니다.\n",
    "\n",
    "KerasTuner로 하이퍼파라미터 튜닝을 할 수 있습니다.\n",
    "\n",
    "TFServing이나 TFLite로 모델을 배포할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-2. 실험실 속 머신러닝 모델\n",
    "MLOps 세상에 온 여러분들 환영합니다!! MLOps는 지금까지 여러분들이 배웠던 인공지능 모델링과 색다른 주제입니다.\n",
    "\n",
    "MLOps를 배우기 전에 우선 MLOps가 무엇이며 어떤 이유에서 나오게 되었으며 주요 Tool들을 배울 예정입니다.\n",
    "\n",
    "MLOps가 무엇일까요?\n",
    "MLOps는 머신러닝(ML)과 Operations(Ops)가 합쳐진 체계를 의미합니다. 기존 머신러닝 특히 딥러닝 파트는 연구 단계에서 많은 발전을 이루었습니다. 이러한 모델들을 실제 서비스에 도입하려고 할 때 소프트웨어적인 문제들이 발생하기 시작했습니다. 그 중 구글은 2015년에 \"Hidden Technical Debt in Machine Learning Systems\"(https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)라는 논문을 발표해 실제 머신러닝 시스템에 숨겨져 있는 소프트웨어적인 기술부채에 대해 언급했습니다.\n",
    "\n",
    "해당 논문에서 머신러닝 시스템을 개발하고 배포하는 것은 비교적 빠르고 비용이 덜 들지만 머신러닝 시스템을 유지하는 것은 어렵고 비용이 많이 들어간다고 이야기합니다. 또한 시스템 유지에 들어가는 기술 부채들은 코드 리팩토링과 같은 코드 수준에서의 부채가 아닌 시스템적인 수준에서 작동하기 때문에 감지되기도 어렵습니다. 해당 문제를 하나씩 살펴보도록 하겠습니다.\n",
    "\n",
    "머신러닝과 소프트웨어 개발 방식의 차이(Complex Models Erode Boundaries)\n",
    "\n",
    "기존에 소프트웨어 개발에서는 캡슐화하고 모듈식으로 설계를 합니다. 모듈로 정리하게 된다면 코드 수준에서 개선이 용이하며 유지관리를 가능하게 만듭니다. 이걸 쉽게 이야기하면 데이터베이스를 정리하는 코드모듈이 따로 있고 웹페이지를 만드는 코드 모듈이 있다고 생각하시면 됩니다. 머신러닝은 어떨까요? 머신러닝은 데이터에 따라서 소프트웨어 로직이 달라지기 때문에 깔끔한 모듈화가 불가능합니다. 예를 들어서 우리가 모델을 학습한다고 진행했을 때 실험을 진행할 때는 Random number를 고정하는 방식을 사용했습니다. 현실 세계의 경우에 추가 학습을 진행하면 파라미터, 학습 설정, 샘플링 방식, 수렴 임계값과 같은 모든 내용이 바뀌게 됩니다. 그렇기에 소프트웨어 프로그래밍 형식으로 머신러닝에 대입하는 건 상당히 어렵습니다.\n",
    "\n",
    "데이터 디펜더시(Data Dependencies Cost More than Code Dependencies)\n",
    "\n",
    "소프트웨어 엔지니어링 환경에서 디펜더시는 코드가 복잡하거나 기술 부채가 쌓여서 생기는 문제였습니다. 예를 들어 다른 엔지니어가 짠 코드가 복잡해서 다른 엔지니어가 건들 수 없고 건드리게 되면 서비스가 마비되는 상황이 있을 수 있습니다. 머신러닝에서의 디펜더시는 코드 수준에서 일어나는 디펜더시도 있지만 데이터 기반으로 일어나는 디펜더시가 더 큰 문제입니다. 머신러닝에서의 코드 디펜더시는 컴파일러로 해결가능하지만 데이터 디펜더시는 기술 부채 쌓는건 비슷하지만 찾는 것부터 어렵습니다. 데이터 디펜더시가 생긴 이유는 몇몇 입력 데이터에서 변환된 신호가 학습을 할때마다 변화할 수 있기 때문입니다. 만일 이러한 입력 신호를 고정되게끔 바꿔버린다고 하면 다른 데이터에 영향을 줄 수 있습니다. 또한 데이터중에서 실제로 그다지 의미가 없는 데이터라 하더라도 마찬가지로 수정을 하면 머신러닝 시스템에 문제를 발생시킬 수 있습니다. 결국 머신러닝 시스템은 데이터에 영향을 받을 수 밖에 없는 시스템이기 때문에 데이터를 수정한다면 머신러닝 전체 시스템에 문제가 발생합니다.\n",
    "\n",
    "피드백 순환루프(Feedback Loops)\n",
    "\n",
    "실험실에서의 머신러닝은 고정된 벤치마크 데이터셋을 이용해서 실험합니다. 그러나 현실에서의 머신러닝은 데이터셋이 고정되어 있지 않습니다. 추천시스템으로 예를 들어 설명하면 여름 데이터셋을 이용해서 만든 머신러닝 모델은 여름에는 잘 작동하지만 계절이 변할 때 정확도가 점점 떨어지게 됩니다. 이를 위해 머신러닝 시스템은 피드백 순환루프를 만들어야 합니다. 더 큰 문제는 한 모델이 여러가지를 수행하는데 피드백을 받아 수정할때 다른 곳에도 영향을 미치는 것입니다. 이런 경우 모델이 문제가 발생하는 것을 알면서도 빠르게 모델 수정을 할 수 없게 되면서 시스템을 마비시킬 수 있습니다.\n",
    "\n",
    "머신러닝의 안티 패턴들(ML-System Anti-Patterns)\n",
    "\n",
    "실험실에서의 머신러닝은 추론과 학습이 실험의 대부분을 차지하지만 실제 머신러닝 시스템에서는 데이터 수집부터 모니터링까지 다양한 영역을 커버하고 있습니다. 그렇다보니 머신러닝 시스템에서 접착 코드가 남발하게 되어 이는 효율성에서 매우 떨어집니다. 또한 실험된 모델을 현실에 급하게 적용하다보면 파이프라인을 복잡하게 설계되면 추후에 문제가 발생할 때 처리하기 어려워집니다.\n",
    "\n",
    "파이프라인이 꼬이고 접착 코드가 남발하면 개별 branch들을 많이 만들어서 실험하게 되고 branch가 많아지게 되면 이전 버전의 호환성 이슈로 비용을 크게 증가시킬 수 있습니다. 그밖에도 데이터가 어떤 타입으로 인코딩 되어있는지, 다양한 라이브러리를 사용해서 만드는 것은 추후 개선작업을 어렵게 만듭니다. 마지막으로 프로토타입을 만드는 것은 좋지만 프로토타입이 현실 세계와 동일하게 작동한다는 착각을 해서는 안됩니다.\n",
    "\n",
    "설정 부채(Configuration Debt)\n",
    "\n",
    "머신러닝은 다른 시스템과 달리 하이퍼 파라미터 설정이 필수적입니다. 이러한 설정값은 해당 feature를 사용하는지, 데이터를 어떤 방식으로 선택하고 사용하는지, 전처리 결과등을 설정합니다. 설정값들은 머신러닝 시스템에서 많은 영향을 끼치지만 실제 연구를 진행할 때 해당 설정값에 대한 검증이나 테스트를 진행하지 않는 경향이 있습니다.\n",
    "\n",
    "현실에서 발생하는 변화들(Dealing with Changes in the External World)\n",
    "\n",
    "앞서 설명한 것처럼 통제된 환경에서 만들어진 머신러닝과 현실세계의 머신러닝 시스템은 차이가 있습니다. 즉 외부 환경으로 인한 유지보수가 지속적으로 발생하고 특정 수치를 조정해야 할 때가 있으며 모니터링과 테스팅을 지속적으로 진행해줘야 합니다. 이를 해결하기 위해서는 자동으로 변화에 따라 대응하는 시스템을 만들어야 합니다.\n",
    "\n",
    "위에 있는 내용을 정리하면 통제된 환경에서 만들어진 머신러닝은 실제 시스템에 적용했을 때 부채가 발생하며 이를 해결해나가야 한다로 정의할 수 있습니다.\n",
    "\n",
    "어떤가요?\n",
    "\n",
    "해당 내용들을 읽었을 때 많이 와닿으셨나요? 몇몇 분들은 공감하실 수 있겠지만... 몇몇 분들은 잘 와닿지 않았을거라 생각합니다.\n",
    "\n",
    "그.래.서. 준비했습니다!!\n",
    "\n",
    "모두의연구소에서 매년 진행하고 있는 컨퍼런스인 MODUCON 영상중에서 2019년에 윤성국님께서 화성에서 온 ML모델러, 금성에서 온 ML 엔지니어 협업하기에 대한 이야기로 발표하셨습니다. 영상 보고 오겠습니다!\n",
    "\n",
    "https://youtu.be/HDYkDQ9HWYg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. 영상에서 설명하는 ML 모델러와 ML 엔지니어는 어떤 차이가 있을까요? 그리고 2개의 직종을 위에 설명한 내용을 기반으로 보면 ML 모델러의 머신러닝과 ML 엔지니어의 머신러닝은 어떤 관점으로 보아야 할까요?\n",
    "\n",
    "A. ML모델러는 수학, 논문, 프로그래밍으로 모델을 직접 설계하며 ML 엔지니어는 프로그래밍, 인프라, 데이터 엔지니어링, 오퍼레이션을 포괄하는 작업을 합니다. 위에 내용으로 볼때 ML 모델러는 실험실에서 연구하는 집단, ML 엔지니어는 현실에서 머신러닝을 적용했을 때 발생하는 문제들을 해결하는 집단입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. 소프트웨어에서 많이 언급하는 CI/CD와 머신러닝 시스템에서의 CI/CD는 어떻게 다르다고 설명하고 있나요?\n",
    "\n",
    "A. 모델 Versioning도 하고 파이프라인을 관리하는 측면에서 동일하나 머신러닝 시스템에서의 CI/CD는 모델 퀄리티, 데이터의 분포, 데이터의 형태를 봐야 합니다. 즉 소프트웨어와 달리 머신러닝은 데이터에 따라 시스템이 변동하기 때문에 차이가 발생합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13-3. MLOps의 정의와 ML 시스템의 구성요소\n",
    "\n",
    "우리는 이전 스텝에서 실험실에서의 머신러닝 모델이 현실과 괴리감이 있다는걸 알았을거라 생각합니다. 이전 성국님 영상에서 ML 엔지니어와 ML 모델러(ML 리서쳐)가 협업이 필요하며 둘의 생각이 사뭇 다르다는것도 알게 되었다고 생각합니다. 그러면 이러한 괴리감을 해결하기 위해서 AI를 활용하는 기업들은 어떻게 해결했을까요?\n",
    "\n",
    "이때 등장한 개념이 바로 MLOps입니다. MLOps가 어떤 개념인지 먼저 살펴보고 가도록 하겠습니다. MLOps를 설명하는데 가장 좋은 영상으로 마이크로소프트에서 만든 애저 듣보잡 MLOps 101 1편을 보도록 하겠습니다.\n",
    "\n",
    "https://youtu.be/q2N6NZKxipg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. MLOps와 DevOps의 차이점이 2개가 있다고 설명합니다. 어떤것일까요?\n",
    "\n",
    "A. 첫번째 차이점은 머신러닝 모델을 만들어나가는 과정이 있기 때문에 머신러닝을 만들고 배포하는 과정이 추가됩니다. 두번째 차이점은 DevOps는 코드로만 이루어져있다면 MLOps는 코드 뿐만 아니라 데이터도 추가해야 합니다. 데이터는 모델을 만들 때도 사용되며 실 서비스가 돌아갈 때도 데이터가 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. MLOps를 도입했을 때 데이터 전문가들은 어떤면에서 좋을까요?\n",
    "\n",
    "A. 파이프라인을 자동화시킬 수 있으며 머신러닝을 production 데이터와 연계할 수 있습니다. 또한 지속적인 모니터링이 가능해지며 재학습과 재배포를 자동화할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머신러닝 시스템의 구성요소\n",
    "\n",
    "MLOps에서의 지속적인 통합, 지속적입 배포, 지속적인 학습을 이해하기 위해서는 우선적으로 머신러닝의 구성요소를 알아야 합니다. 이전 스텝에서 보았던 구글에서 나온 논문 \"Hidden Technical Debt in Machine Learning System\"에 머신러닝 시스템의 구성요소가 그림으로 나타냈습니다.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/mlops_2015_paper_Gdw5hED.max-800x600.png)\n",
    "\n",
    "[[출처 : Hidden Technical Debt in Machine Learning Systems]]\n",
    "머신러닝 시스템을 구성하는 도구는 춘추전국시대라 불릴만큼 각 요소마다 다양합니다. 이번 스텝에서는 각 항목이 어떤걸 의미하는지 알아보고 각 항목에서 자주 사용하고 있는 도구를 알아보도록 하겠습니다.\n",
    "\n",
    "#### 설정(Configuration)\n",
    "\n",
    "머신러닝에서 설정은 learning rate이나 weight decay와 같은 하이퍼파라미터 뿐만 아니라 데이터를 모을 때 어떤 방식으로 모아야 하고 ML 모델을 설계할 때 사용할 프레임워크, 서빙할 때 진행하는 방식과 같은 머신러닝 시스템에 전반적인 기획 내용을 포괄하고 있습니다. 해당 설정이 완료되어야 머신러닝 시스템을 설계할 때 방향성이 흔들리지 않습니다.\n",
    "\n",
    "#### 데이터 수집 (Data Collection)\n",
    "\n",
    "머신러닝 시스템에서의 데이터 수집은 가장 중요한 스텝입니다. AlexNet부터 현재 최신 모델들까지 전부 데이터의 중요성을 이야기하고 있습니다. 2023년 초를 강타한 GPT-4도 높은 수준의 데이터뿐만 아니라 다양한 데이터를 사용하고 있습니다. 그렇기에 좋은 데이터 수집은 좋은 모델이 나오게 하는 원동력으로 작용합니다.\n",
    "\n",
    "#### 특성 추출(Feature Extraction)\n",
    "\n",
    "데이터 수집이 완료되었으면 해당 데이터에 대한 특성을 추출하는 작업이 필요합니다. 데이터에서 특성을 추출해서 데이터에 유용한 정보를 얻으면 우리가 갖고 있는 데이터에 대한 이해도가 높아지게 됩니다. 이를 기반으로 우리는 머신러닝 시스템에서 분석 도구나 머신러닝 모델을 만들 때 사용하게 됩니다.\n",
    "\n",
    "#### 데이터 검증 (Data Verification)\n",
    "\n",
    "데이터를 수집할 때도 품질확인하는 것도 중요하지만 다시 한번 검증과정을 거쳐 실제 데이터가 정확하고 사용가능한지를 확인해야 한다. 데이터 검증(Data Verification)은 데이터 확인(Data Validation)과 목적에 있어서 차이를 보입니다. 데이터 검증(Data Verfication)은 데이터를 수집할 때 해당 데이터를 넣으면 정확도가 올라가고 지속적이라는걸 보장하기 위해서 데이터를 체크합니다. 반면에 데이터 확인(Data Validation)은 데이터가 모델에서 허용하는 범위에 있는지를 확인하는 작업입니다. 그렇기에 머신러닝 시스템은 고품질의 데이터를 지속적으로 모으고 해당 데이터로 모델 성능이 올라가는 것에 목적이 있기에 데이터 검증이 필수적입니다.\n",
    "\n",
    "#### 분석 도구 (Analysis Tools)\n",
    "\n",
    "머신러닝 모델을 만들었다면 머신러닝 모델이 잘 만들어졌는지 확인하는 분석 도구가 필요합니다. 물론 머신러닝을 만들 때 손실(loss)값이나 정확도(accuracy)로도 분석가능하지만 모델을 여러번 돌리는 실험에서는 해당 내용을 하나의 대시보드로 보고 확인하는 작업이 필요합니다. 뿐만 아니라 하이퍼 파라미터를 튜닝이 필요할 때도 해당 분석도구로 보여주는 대시보드는 큰 힘을 갖게 됩니다. 해당 분석도구의 대표적인 사례로 TensorBoard, W&B, mlflow 등이 있습니다.\n",
    "\n",
    "#### 프로세스 관리 툴(Process Management Tools)\n",
    "\n",
    "머신러닝 시스템이 자연스럽게 흘러가는걸 확인하려면 데이터의 흐름에 따라 시스템이 잘 운영되는지를 확인해야 합니다. 프로세스 관리 툴은 우리가 만든 시스템에 이상유무를 판단하는 툴입니다. 해당 툴의 대표적인 사례로 airflow, TFX, Kubeflow가 있습니다. 3가지 툴 모두 워크플로우를 구성할 수 있으며 스케줄링과 모니터링 기능까지 갖춰져있습니다. 실제 3가지 툴 모두 많은 기업들이 사용하고 있으며 각 회사의 도입기가 블로그로 작성되어 있습니다.\n",
    "\n",
    " - 마켓컬리의 Kubeflow 도입기(https://helloworld.kurly.com/blog/second-mlops/)\n",
    "  \n",
    " - 오늘의집의 Airflow 도입기(https://www.bucketplace.com/post/2021-04-13-%EB%B2%84%ED%82%B7%ED%94%8C%EB%A0%88%EC%9D%B4%EC%8A%A4-airflow-%EB%8F%84%EC%9E%85%EA%B8%B0/)\n",
    "  \n",
    " - 스캐터랩의 TFX 도입기(https://tech.scatterlab.co.kr/use-tfx-pipeline-with-customization/)\n",
    "\n",
    "#### 리소스 관리 (Machine Resource Management)\n",
    "\n",
    "머신러닝 시스템에서 모델을 학습할 때 필요한 GPU와 같은 리소스 관리가 필요합니다. 특히 GPU를 2대 이상 사용할 경우에는 분산학습을 진행해야 하기 때문에 리소스 관리 툴이 필요합니다. 만일 클라우드 GPU를 사용할 경우에 관리를 제대로 하지 않을 경우 비용이 과다하게 나오기 때문에 특별한 관리가 필요합니다. 해당 리소스 관리의 경우 쿠버네티스와 같은 오케스트레이션 툴뿐만 아니라 TerraForm과 같은 코드로 인프라를 관리하는 툴도 있습니다.\n",
    "\n",
    "인프라 배포 (Serving Infrastructure)\n",
    "\n",
    "머신러닝을 실제 서비스로 진행하기 위해서는 머신러닝 모델을 배포하는 것 또한 중요합니다. 머신러닝 모델을 실제 배포하는 방법에는 모델 예측 결과를 Database에 저장하여 사용하는 방식이 있거나 API를 사용하는 방식이 있습니다. BentoML과 Gradio가 대표적인 인프라 배포 툴로 유명합니다.\n",
    "\n",
    "모니터링(Monitoring)\n",
    "\n",
    "마지막으로 모델을 모니터링하면서 해당 모델이 추가적으로 학습이 필요한 상황인지 분석합니다. 모니터링을 진행하면서 새로 학습을 진행할 경우에는 기존에 로그로 쌓아놓았던 데이터를 사용할지 혹은 아예 새로운 데이터로 만들지를 결정하는 단계입니다. 모니터링의 경우 Google Cloud에서 사용하고 있는 VertexAI가 대표적인 서비스입니다.\n",
    "\n",
    "MLOps에 대한 정의와 머신러닝에 대한 구성요소와 대표적인 툴들을 정리하면서 설명했습니다. 근데 실제로 그럴까요? 2023년 3월에 마키나락스가 모두의연구소에서 글로벌 MLOps 트렌드와 한국형 MLOps 전략에 대해 강연을 진행했습니다.\n",
    "\n",
    "한번 보고 오시죠!!\n",
    "\n",
    "https://youtu.be/DRIEKB9smBY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13-4. TFX (TensorFlow Extended) 소개하기\n",
    "우리가 MLOps를 하기 위해서 사용할 오픈소스 플랫폼은 바로 TFX(TensorFlow Extended)입니다. TFX는 고성능 머신러닝 작업을 위해 설계된 머신러닝 파이프라인 오픈소스 플랫폼로 다양한 Component들이 TFX로 빌드가능하며 개별적으로도 사용할 수 있습니다. 사실 MLOps를 다루는 머신러닝 파이프라인은 Apache에서 나온 Airflow, 쿠버네티스 기반의 플랫폼인 Kubeflow, 오픈소스 플랫폼인 MLflow가 있습니다. 이러한 오픈소스 플랫폼들보다 TFX가 갖고 있는 장점이 어떤 것이 있을까요?\n",
    "\n",
    "### TFX의 장점\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/mlflow_airflow_tfx.max-800x600.png)\n",
    "\n",
    "[MLOps의 대표적인 툴들 (mlflow, airflow, Kubeflow)]\n",
    "\n",
    "TFX가 다른 오픈소스 플랫폼들보다 좋은 이유로는 TFX 단일 오픈소스 플랫폼로 End-to-End로 구현가능하다는 점입니다. Airflow는 범용적인 목적을 가진 task orchestration만을 지원하지만 Kubeflow는 머신러닝에서의 workflow orchestration과 Model management, notebook workspace까지 지원합니다. 그렇지만 Kubeflow는 Kubernetes를 구동해야 하기 때문에 리소스를 많이 먹는 편입니다. MLflow의 경우 간단하게 사용할 수 있고 Jupyter Notebook까지 지원합니다. 그러나 MLflow에는 하이퍼파라미터 튜닝을 지원하지 않는 단점을 갖고 있습니다.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/tfx.max-800x600.png)\n",
    "[TensorFlow Extended]\n",
    "\n",
    "한편 TFX는 컴포넌트로 관리하기 때문에 다양한 환경에서 사용할 수 있게 만들었습니다. CSV뿐만 아니라 BigQuery를 활용할 수도 있으며 Kubeflow pipeline으로 커스터마이징도 가능합니다. 뿐만 아니라 Google Cloud와의 연계도 뛰어나 Vertex AI를 활용하면 TFX 적용이 상당히 쉽습니다. 뿐만 아니라 TFX는 CPU/GPU같은 환경에 상관없이 사용가능합니다.\n",
    "\n",
    "그러나.. TFX라고 장점만을 갖고 있는 것은 아닙니다. 컴포넌트 단위로 관리하기 때문에 파이프라인이 복잡해지면 설정 값의 의미가 퇴색되기도 하고 설정값이 어떤 컴포넌트에 영향을 주는지 알 수 없는 상황이 오기도 합니다. 또한 TFX의 경우 2021년 7월 23일에 1.0버전이 나와 다른 플랫폼과 비교했을 때 상당히 늦게 나왔습니다. 그럼에도 강력한 성능을 갖고 있으며 우리나라 회사에서는 당근마켓과 스캐터랩이 도입해서 사용하고 있습니다.\n",
    "\n",
    "- 스캐터랩 - TFX 머신러닝 파이프라인 사용하기(https://tech.scatterlab.co.kr/use-tfx-pipeline-with-customization/)\n",
    "  \n",
    "- 당근마켓 - TFX와 함께 머신러닝 파이프라인 개발하기(https://medium.com/daangn/tfx%EC%99%80-%ED%95%A8%EA%BB%98-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0-4578f030a9c1)\n",
    "\n",
    "### TFX의 구성요소 - 컴포넌트\n",
    "TFX는 위에서 설명했던 것처럼 컴포넌트들로 구성되어 있습니다. 컴포넌트는 표준 컴포넌트와 커스터마이징이 된 컴포넌트로 구성되어 있습니다. 우리가 살펴볼 컴포넌트는 표준 컴포넌트들로 TFX에서 자주 사용될 뿐만 아니라 가장 중요한 뼈대입니다.\n",
    "\n",
    "#### ExampleGen\n",
    "\n",
    "ExampleGen TFX pipeline 컴포넌트는 데이터를 TFX Pipeline으로 넣는 컴포넌트입니다. 해당 컴포넌트는 CSV파일이나 TFRecord 혹은 BigQuery와 같은 외부 데이터 소스로 받고 출력은 tf.Example Record와 tf.SequenceExample records 혹은 .proto파일(proto buffer는 Google에서 개발한 데이터 직렬화 구조입니다. 자세한 내용은 여기를 참고해주세요!)로 나오게 됩니다.\n",
    "\n",
    "ExampleGen은 데이터를 SchmaGen, StatisticsGen, Example Validat와 같은 TensorFlow Data Validation 라이브러리에서 사용하는 컴포넌트들로 데이터를 제공합니다. 또한 TensorFlow Transform library에서 사용하는 Transform에도 데이터를 제공하는 역할까지 하며 inference하는 동안에 대상을 배포할때도 사용합니다.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/ExampleGen.png)\n",
    "[[ExampleGen 예시]\n",
    "\n",
    "#### StatisticsGen, SchemaGen, ExampleValidator\n",
    "\n",
    "StatisticsGen은 이전에 만들었던 ExampleGen 컴포넌트 출력을 입력으로 수락한 다음 통계를 생성하는 컴포넌트입니다. 해당 컴포넌트의 경우 대화형 콘텍스트에서 출력한 다음 시각화 또한 가능합니다.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/StatisticsGen.max-800x600.png)\n",
    "[[StatisticsGen 예시]\n",
    "\n",
    "SchemaGen은 스키마가 없을 경우 스키마를 생성하는 컴포넌트입니다. 해당 컴포넌트를 실행하면 스키마를 검토한 후 사용할 수 있습니다.\n",
    "\n",
    "ExampleValidator는 훈련 및 제공 데이터에 있는 문제점을 식별하는 컴포넌트입니다. ExampleValidator는 StatisticsGen 컴포넌트에 의해 계산된 데이터 통계를 Schema와 비교해서 예제 데이터에서 문제를 뽑아낼 수 있습니다.\n",
    "\n",
    "#### Transform\n",
    "\n",
    "Transform 컴포넌트는 흔히 텐서플로 변환(TensorFlow Transform)이라고 불리며 데이터 전처리단계로 텐서플로우 그래프를 구성할 수 있습니다. TensorFlow Transform은 위에서 생성된 데이터 스키마를 사용해 파이프라인에 수집된 데이터를 전처리하며 결과물을 전처리 그래프로 시각화할 수 있게 출력하거나 머신러닝 모델을 내보낼 때 사용합니다. 또한 파이프라인의 Trainer 컴포넌트에서도 사용할 수 있게 변환합니다. Transform은 자연어처리에서의 ngram,bag of words, TFIDF등에 적용가능하며 컴퓨터 비전에서는 이미지를 디코딩하며 픽셀까지 조정가능합니다.\n",
    "\n",
    "TensorFlow Transform은 단독으로도 사용할 수 있지만 Apache Beam에 이식해서 사용할 수 있습니다. Apache Beam은 배치 및 스트리밍 데이터 처리 파이프라인을 정의하고 실행하는 오픈 소스 통합 프로그래밍 모델입니다. 빔에 이식해서 사용할 경우 생산 환경에 모델을 더 쉽게 배포할 수 있고 Apache Beam을 메인으로 사용하고 TensorFlow Transform을 서브로 사용해 더 쉽게 관리할 수 있습니다.\n",
    "\n",
    "#### Trainer\n",
    "\n",
    "Trainer는 TensorFlow로 모델을 작성하고 모델학습 코드를 만들고 해당 코드를 TFX에 통합시켜 파이프라인의 학습 단계를 처리하는 컴포넌트입니다. Trainer 컴포넌트를 학습하려면 컴파일된 Keras 모델이 필요하기 때문에 Trainer컴포넌트가 작동하는 함수에는 반드시 케라스 모델이 있어야 합니다. Trainer 컴포넌트에서 모델 학습 API에서 fit 메소드를 사용해야 합니다. 이 함수들을 기반으로 Trainer 컴포넌트가 실행되면 savedModel을 사용해서 모델을 저장할 수 있습니다. 또한 Trainer 컴포넌트에 텐서보드를 연결해 모델의 프로파일을 생성해 성능 병목 현상이 파악가능합니다.\n",
    "\n",
    "#### Tuner\n",
    "\n",
    "TFX의 Tuner는 Keras에서 사용하는 KerasTuner와 Google Cloud Platform에서 제공하는 Tuner를 사용할 수 있습니다. KerasTuner의 경우 코드로 제어할 수 있어 쉽게 하이퍼파라미터 튜닝을 할 수 있으며 병렬 튜닝도 지원해 효율성도 보장됩니다. 또한 KerasTuner에는 Oracle이라는 알고리즘으로 튜닝을 진행하는데 기본적으로 많이 사용되는 Grid Search나 Random Search뿐만 아니라 Bayesian Optimization도 지원해 하이퍼파라미터의 잠재적 최적값을 구할 수 있습니다. Google Cloud Platform에서 제공하는 CloudTuner는 KerasTuner에서 사용하는 알고리즘을 전부 사용가능하지만 클라우드 비용이 발생하는 단점을 갖고 있어 TFX에서의 Tuner는 대부분 KerasTuner를 사용합니다.\n",
    "\n",
    "#### Evaluator, Pusher\n",
    "\n",
    "Evaluator 컴포넌트는 TensorFlow Model Analysis라는 라이브러리를 활용해 검증 데이터셋 에 대한 모델 예측을 평가합니다. TensorFlow Model Analysis는 Trainer 컴포넌트가 내보낸 모델을 기반으로 지표를 계산하는 라이브러리입니다. 텐서보드의 경우 모델 학습 중 미니배치상에 추론된 대략적인 지표만 제공하지만 해당 라이브러리는 전체 평가 데이터셋에 거쳐 지표를 계산합니다. Evaluator 컴포넌트는 TFX에서 TFMA를 구현하기 위해 사용하는 것입니다.\n",
    "\n",
    "한편 Pusher 컴포넌트는 Evaluator 컴포넌트가 모델을 승인했는지 확인하고 승인받았다면 모델을 서빙 파일 경로로 밀어넣는 컴포넌트입니다. Pusher를 진행하게 된다면 텐서플로 서빙에서 모델을 선택할 수 있게 됩니다.\n",
    "\n",
    "#### TensorFlow Serving\n",
    "\n",
    "TensorFlow Serving은 텐서플로우 그래프를 배포할 수 있으며 표준화된 엔드포인트로 그래프에서 예측할 수 있게 하는 라이브러리입니다. TensorFlow Serving은 모델 및 버전 관리를 처리하고 정책 기반으로 모델을 서비스하고 다양한 소스에서 모델을 로드할 수 있습니다. TensorFlow Serving은 저장된 모델에 대한 REST API추론 서버를 만들어내서 결과값을 반환합니다.\n",
    "\n",
    "그렇다면 이번 노드에서 공부할 내용은?\n",
    "TFX는 다양한 컴포넌트들이 존재하며 이를 공부하기 위해서는 많은 시간이 소요됩니다. 이번 노드에서는 우리가 바로 사용할 수 있는 동시에 매우 쉽게 사용할 수 있는 컴포넌트 2개를 사용할 예정입니다. 바로 KerasTuner와 TensorFlow Serving입니다.\n",
    "\n",
    "KerasTuner를 통해서 여러분들이 Keras로 모델을 만들었을때 하이퍼파라미터 튜닝을 쉽게 할 수 있도록 도와줄겁니다. 또한 TensorFlow Serving은 모델을 REST API추론 서버를 만들게 됨으로써 어플리케이션화시킬 수도 있다고 생각합니다. 그렇다면 재미있는 KerasTuner와 TensorFlow Serving의 세계에 빠져볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13-5. 모델을 더 완벽하게 만드는 방법 : KerasTuner\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/kera-tuner.max-800x600.png)\n",
    "\n",
    "[Keras-Tuner 소개]\n",
    "우리가 볼 첫번째 MLOps는 하이퍼파라미터 튜닝입니다. 그중에서 우리가 사용할 툴은 KerasTuner입니다.\\\n",
    "\n",
    "KerasTuner는 Keras뿐만 아니라 scikit-learn과 같은 모델에서도 커스터마이징해서 사용할 수 있는 툴이며 하이퍼파라미터 튜닝을 자동으로 할 수 있게 도와줍니다.\n",
    "\n",
    "기존 모델에서 하이퍼파라미터 튜닝을 진행한다고 했을 때 딥러닝의 경우 일일이 바꿔가면서 함수를 만들고 정리했습니다. 그러나 KerasTuenr를 사용하고 범위를 결정하는 함수를 잘 선택한다면 하이퍼파라미터 튜닝을 원하는대로 할 수 있습니다.\n",
    "\n",
    "그렇다면 KerasTuner를 사용하러 떠나볼까요?\n",
    "\n",
    "이번 실습은 MNIST로 간단하게 할 수 있는 하이퍼파라미터 튜닝작업입니다!\n",
    "\n",
    "우선 디렉토리 먼저 만들어놓도록 하겠습니다.\n",
    "\n",
    "이번 실습에 앞서 우선 KerasTuner를 설치하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘aiffel/mlops’: File exists\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-tuner in /home/ralphpark/.local/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: keras-core in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-tuner) (0.1.7)\n",
      "Requirement already satisfied: kt-legacy in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: requests in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: packaging in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: namex in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.0.7)\n",
      "Requirement already satisfied: dm-tree in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (0.1.8)\n",
      "Requirement already satisfied: rich in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (13.5.3)\n",
      "Requirement already satisfied: numpy in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.24.3)\n",
      "Requirement already satisfied: absl-py in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: h5py in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner) (3.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ralphpark/.local/lib/python3.10/site-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ralphpark/.local/lib/python3.10/site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ralphpark/.local/lib/python3.10/site-packages (from requests->keras-tuner) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ralphpark/.local/lib/python3.10/site-packages (from requests->keras-tuner) (3.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ralphpark/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ralphpark/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ralphpark/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!mkdir aiffel/mlops\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/ralphpark/.local/lib/python3.10/site-packages (1.3.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ralphpark/.local/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ralphpark/.local/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/ralphpark/.local/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ralphpark/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 03:57:31.312706: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-27 03:57:32.185465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 이번에 사용할 데이터셋은 MNIST입니다. keras에 내장되어 있는 datasets으로 불러오겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN을 사용할 예정이라 차원 수를 하나 더 추가해줍니다.\n",
    "또한 label을 categorical을 활용해 변환합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.reshape(-1,28, 28, 1) \n",
    "X_test = x_test.reshape(-1,28,28,1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn에 내장되어 있는 train_test_split으로 train data와 validation data를 나누어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1)\n",
      "(12000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 제가 짠 DeepTuner를 살펴보겠습니다!\n",
    "\n",
    "DeepTuner의 경우 kerastuner.Tuner를 인자로 하는 class이며 class에서 수행하는 함수는 run_trial, save_model load_model입니다.\n",
    "\n",
    "run_trial 함수에서 제일 중요한 부분은 hypermodel과 trial입니다.\n",
    "\n",
    "KerasTuner에서의 hypermodel은 모델을 공유 및 재사용하기 위해 검색 공간을 캡슐화하는 모델입니다. hypermodel의 경우 hp라는 인수를 활용해서 keras.Model을 생성합니다.\n",
    "즉 hypermodel은 우리가 만들고 싶은 모델을 쌓는 과정을 거치는데 이때 하이퍼파라미터 튜닝에 대한 검색공간을 만들어줄때 hp라는 인수를 사용해서 만든 모델입니다.\n",
    "hypermodel의 경우 build 메소드를 활용하면 모델이 빌드가 되면서 하이퍼파라미터 튜닝이 시작합니다.\n",
    "\n",
    "trial의 경우에는 Oracle에 속하는 class입니다.\n",
    "Oracle이란 KerasTuner의 모든 검색 알고리즘에서 사용하는 기본 클래스이며 크게 RandomSearchOracle, BayesianOptimizationOracle, HyperbandOracle이 있습니다.\n",
    "쉽게 설명하면 Oracle은 KerasTuner가 하이퍼파라미터를 정할 때 사용하는 알고리즘이라고 생각하시면 됩니다!\n",
    "여기서 trial.hyperparameter는 Oracle이 찾아야 하는 하이퍼파라미터입니다. 즉 hypermodel에서의 hp입니다.\n",
    "제가 model.fit()을 할때 batch_size도 고를 수 있게 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepTuner(kt.Tuner):\n",
    "    def run_trial(self, trial, X, y, validation_data, **fit_kwargs):\n",
    "        model = self.hypermodel.build(trial.hyperparameters)\n",
    "        model.fit(X, y, batch_size=trial.hyperparameters.Choice(\n",
    "            'batch_size', [16, 32]), **fit_kwargs)\n",
    "\n",
    "\n",
    "        X_val, y_val = validation_data\n",
    "        eval_scores = model.evaluate(X_val, y_val)\n",
    "        return {name: value for name, value in zip(\n",
    "            model.metrics_names,\n",
    "            eval_scores)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 build_model쪽을 보도록 하겠습니다.\n",
    "\n",
    "build_model은 위에서 설명한것처럼 hypermodel을 만들어줘야 합니다. 제가 만든 hypermodel은 총 2가지 기법이 들어가 있으며 주의사항도 1가지 있습니다.\n",
    "\n",
    "우선 주의사항부터 말씀드리면 해당 모델의 경우 hypermodel이기 때문에 Input지정이 필수입니다!\n",
    "그렇기에 여러분들이 넣고 싶은 모델에 대한 shape을 꼭 기재해주셔야 합니다!\n",
    "\n",
    "제가 사용한 첫번째 기법은 바로 layer의 숫자도 KerasTuner에게 맡겼습니다.\n",
    "for문을 확인해보겠습니다\n",
    "\n",
    "첫번째 for문의 경우 hp.Int로 만들어 검색공간은 정수로 만들고 가장 작은값을 1로 가장 큰값을 10으로 두었습니다.\n",
    "이렇게 설정하면 최소 1개에서 최소 10개의 layer를 쌓을 수 있게 설정할 수 있습니다.\n",
    "\n",
    "제가 쌓고싶은 layer는 conv2D인데 kernel_size는 (3,3)이며 차원수는 최소 32에서 최대 256으로 바꾸었습니다.\n",
    "\n",
    "두번째 for문을 살펴보겠습니다. 두번째 for문도 최소 1개에서 3개로 설정했지만 Dense Layer의 경우 나올 수 있는 차원을 32,64,128,256중 1개를 선택하도록 만들었습니다.\n",
    "\n",
    "이러한 방식으로 hypermodel을 만들면 하고싶은 하이퍼 파라미터 튜닝을 진행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape = X_train.shape[1:], name = 'inputs'))\n",
    "    for i in range(hp.Int('num_layers', min_value=1, max_value=10)):\n",
    "              model.add(tf.keras.layers.Conv2D(hp.Int(\n",
    "                  'units_{i}'.format(i=i), min_value=32, max_value=128, step=5), (3,3),activation='relu'))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for i in range(hp.Int('n_connections', 1, 3)):\n",
    "        model.add(tf.keras.layers.Dense(hp.Choice(f'n_nodes',\n",
    "                                  values=[32,64,128, 256]), activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax', name = 'outputs'))\n",
    "    model.compile(optimizer = 'adam',loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 keras_tuner를 정의하고 탐색하는것까지 보도록 하겠습니다.\n",
    "\n",
    "저는 이번 모델의 경우 BayesianOptimizationOracle을 사용할 예정이며 목표는 accuracy와 max로 둘 예정입니다. 실제 trial은 10번으로 지정할 것입니다.\n",
    "\n",
    "hypermodel은 build_model을 넣어주시고 project이름도 작성해주세요.\n",
    "\n",
    "마지막으로 search함수에 X_train, Y_train, validation data, epoch을 넣고 탐색합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-tuner[bayesian] in /home/ralphpark/.local/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: keras-core in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-tuner[bayesian]) (0.1.7)\n",
      "Requirement already satisfied: requests in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-tuner[bayesian]) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-tuner[bayesian]) (1.0.5)\n",
      "Requirement already satisfied: packaging in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-tuner[bayesian]) (23.1)\n",
      "Requirement already satisfied: scikit-learn in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-tuner[bayesian]) (1.3.1)\n",
      "Requirement already satisfied: scipy in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-tuner[bayesian]) (1.11.2)\n",
      "Requirement already satisfied: numpy in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner[bayesian]) (1.24.3)\n",
      "Requirement already satisfied: absl-py in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner[bayesian]) (1.4.0)\n",
      "Requirement already satisfied: rich in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner[bayesian]) (13.5.3)\n",
      "Requirement already satisfied: namex in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner[bayesian]) (0.0.7)\n",
      "Requirement already satisfied: dm-tree in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner[bayesian]) (0.1.8)\n",
      "Requirement already satisfied: h5py in /home/ralphpark/.local/lib/python3.10/site-packages (from keras-core->keras-tuner[bayesian]) (3.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ralphpark/.local/lib/python3.10/site-packages (from requests->keras-tuner[bayesian]) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ralphpark/.local/lib/python3.10/site-packages (from requests->keras-tuner[bayesian]) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ralphpark/.local/lib/python3.10/site-packages (from requests->keras-tuner[bayesian]) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ralphpark/.local/lib/python3.10/site-packages (from requests->keras-tuner[bayesian]) (3.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ralphpark/.local/lib/python3.10/site-packages (from scikit-learn->keras-tuner[bayesian]) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ralphpark/.local/lib/python3.10/site-packages (from scikit-learn->keras-tuner[bayesian]) (3.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ralphpark/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner[bayesian]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ralphpark/.local/lib/python3.10/site-packages (from rich->keras-core->keras-tuner[bayesian]) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ralphpark/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner[bayesian]) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras-tuner[bayesian]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 41s]\n",
      "accuracy: 0.9763333201408386\n",
      "\n",
      "Best accuracy So Far: 0.9869166612625122\n",
      "Total elapsed time: 00h 07m 49s\n"
     ]
    }
   ],
   "source": [
    "my_keras_tuner = DeepTuner(\n",
    "    oracle=kt.oracles.BayesianOptimizationOracle(\n",
    "        objective=kt.Objective('accuracy', 'max'),\n",
    "        max_trials=10,\n",
    "        seed=42),\n",
    "    hypermodel=build_model,\n",
    "    overwrite=True,\n",
    "    project_name='my_keras_tuner')\n",
    "\n",
    "# 해당 모델 학습시간은 약 10분정도 걸립니다!\n",
    "my_keras_tuner.search(\n",
    "    X_train, y_train, validation_data=(X_val, y_val), epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 좋은 모델을 뽑는 방법은 KerasTuner.get_best_hyperparamters를 이용해서 가장 좋은 하이퍼파라미터를 뽑아내는 작업입니다\n",
    "하이퍼파라미터를 뽑았으면 build_model()에 집어넣어 가장 좋은 모델을 선언합니다.\n",
    "\n",
    "그렇다면 여러분들이 만든 가장 좋은 모델을 확인해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_65 (Conv2D)          (None, 26, 26, 102)       1020      \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 24, 24, 42)        38598     \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 22, 22, 67)        25393     \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 20, 20, 37)        22348     \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 18, 18, 52)        17368     \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 16848)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               4313344   \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4420641 (16.86 MB)\n",
      "Trainable params: 4420641 (16.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_hps = my_keras_tuner.get_best_hyperparameters(num_trials=10)[0]\n",
    "model = build_model(best_hps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최고의 하이퍼 파라미터만 뽑았기 때문에 아직 모델학습이 되지 않았습니다!\n",
    "이번에 epoch을 5번정도 주어서 모델학습을 진행합니다!\n",
    "\n",
    "만일 여러분들이 무거운 모델을 돌릴 경우 하이퍼파라미터 튜닝작업이 매우 느려질 수 있습니다.\n",
    "그때의 경우 하이퍼파라미터 튜닝할때 epoch을 3-4정도로 작게 준 다음 최고의 하이퍼파라미터를 뽑아낸 다음\n",
    "본격적인 모델학습때 epoch을 넉넉하게 주는 것도 방법입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.1520 - accuracy: 0.9604\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0484 - accuracy: 0.9847\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0358 - accuracy: 0.9891\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0267 - accuracy: 0.9915\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0208 - accuracy: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb8f3acc580>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 평가를 진행해볼까요? ㅎㅎ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.058003418147563934, 0.9869999885559082]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 저장할 차례입니다.\n",
    "\n",
    "우리가 이전까지 자주 사용한 저장방법은 HDF5파일 (.h5)로 저장하는 방법이었습니다.\\\n",
    "\n",
    "HDF파일로 저장하는 방식은 이전 Keras에서 모델을 저장하는 방식이었으나 사실 이 방법은 TensorFlow나 Keras에서 그다지 선호하지 않는 저장방식입니다.\\\n",
    "\n",
    "TensorFlow의 경우 공식적으로 지원하는 모델 저장방식은 SavedModel입니다.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/tree.png)\n",
    "\n",
    "[SavedModel 파일구조]\n",
    "\n",
    "SavedModel은 .h5파일처럼 모델의 가중치와 모델을 전부 하나의 파일로 관리하는 방식이 아닌 모델, 가중치를 따로 구분해서 저장하는 방식입니다.\n",
    "\n",
    "SavedModel은 크게 3가지로 구성되어 있습니다.\n",
    "\n",
    "- saved_model.pb : pb는 프로토콜 버퍼를 의미하며 해당 파일은 내보낸 모델 그래프 구조를 포함하고 있습니다.\n",
    "- variables : 내보낸 변수값이 있는 이진 파일과 내보낸 모델 그래프에 해당하는 체크포인트를 포함하고 있습니다\n",
    "- assets : 내보낸 모델을 불러올 때 추가적인 파일이 필요한 경우 이 폴더에 파일이 생성됩니다.\n",
    "\n",
    "이 방식으로 진행한다면 모델을 배포할 때 유리합니다.\n",
    "\n",
    "Keras의 경우 .keras파일을 선호합니다. .keras파일은 .h5파일과 마찬가지로 가중치와 모델을 전부 하나의 파일로 관리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ralphpark/aiffel5_quest/exploration/aiffel/mlops/best_model/1/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ralphpark/aiffel5_quest/exploration/aiffel/mlops/best_model/1/model/assets\n"
     ]
    }
   ],
   "source": [
    "save_path = os.getenv('HOME') + '/aiffel5_quest/exploration/aiffel/mlops/best_model/1'\n",
    "fname = os.path.join(save_path, 'model')\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13-6. 이제는 모델을 배포할 차례! : TFServing & TFLite\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/tfserving.max-800x600.png)\n",
    "\n",
    "[GitHub에 있는 TFServing 설명]\n",
    "\n",
    "모델을 만들었다면 이제는 배포를 진행해봐야죠!\n",
    "\n",
    "배포를 진행하는 방법은 크게 2가지로 나눌 수 있습니다.\n",
    "\n",
    "클라우드를 활용해서 모델을 배포하는 방식\n",
    "경량화된 모델을 만들어서 휴대폰같은 디바이스에서도 모델이 실행되게 만드는 방식\n",
    "TensorFlow는 첫번째 방식을 TFServing을 통해서 가능하게 만들며 2번째 방식은 TFLite방식으로 가능하게 만듭니다.\n",
    "그렇다면 2개를 더 자세하게 알아볼까요?\n",
    "\n",
    "### TFServing\n",
    "\n",
    "TFServing이란 텐서플로우 그래프를 배포할 수 있으며 표준화된 엔드포인트를 제공합니다. 또한 모델 및 버전관리가 가능하며 정책 기반으로 모델을 서비스할 수 있습니다.\n",
    "또한 지연 시간이 최대한 짧게 만드는 고성능 처리량에서도 초점을 맞추고 있습니다.\\\n",
    "\n",
    "TFServing을 하는 방식은 크게 2가지가 있습니다.\n",
    "\n",
    "- Docker를 활용한 배포\n",
    "- 우분투 터미널을 활용한 배포\n",
    "  \n",
    "이번에 2개 모두 설명할 예정입니다.\n",
    "\n",
    "주의사항 우분투 터미널 실습의 경우 실제 결과물이 나오려면 로컬에서 진행해야 합니다.\n",
    "LMS에서 실행되지 않는 이유는 LMS 시스템에 들어가 있는 GPU클라우드도 Docker Image이며 쿠버네티스로 관리되고 있습니다.\n",
    "그렇기에 WSL2와 Docker 환경세팅을 해주세요..!!\n",
    "\n",
    "WSL2 설치 + 윈도우에서 Docker 설치하기(https://axce.tistory.com/121)\n",
    "\n",
    "파일을 우분투 디렉토리로 옮기는 방법(https://bbeomgeun.tistory.com/139)\n",
    "\n",
    "macOS에서 Docker 설치하기(https://kplog.tistory.com/288)\n",
    "\n",
    "#### TFServing 우분투 터미널로 실습하기\n",
    "\n",
    "우선 우분투 터미널 실습부터 진행하겠습니다!\n",
    "\n",
    "클라우드 쉘을 열고 해당 스크립트를 넣어주세요!\n",
    "\n",
    "```bash\n",
    "$ echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
    "$ sudo apt update\n",
    "$ sudo apt install tensorflow-model-server\n",
    "```\n",
    "\n",
    "해당 스크립트는 우분투에 tensorflow-model-server를 설치해 배포용 텐서플로우 서버를 구축하는 것입니다!\n",
    "\n",
    "그 다음 스크립트는 모델을 배포하는 스크립트입니다.\n",
    "\n",
    "```bash\n",
    "$ tensorflow_model_server --port=8500 \\\n",
    "\t\t\t\t\t\t --rest_api_port=8501 \\\n",
    "\t\t\t\t\t\t --model_name=my_model \\\n",
    "\t\t\t\t\t\t --model_base_path=/aiffel/mlops/best_model/model \n",
    "```\n",
    "여기서 model_base_path는 실제 SavedModel을 넣은 디렉토리로 바꿔주세요! (주의사항) SavedModel을 넣을 때 model 디렉토리 내부에 숫자 '1' 폴더를 만들고 넣어주세요!\n",
    "\n",
    "#### TFServing Docker로 실습하기\n",
    "\n",
    "Docker를 설치하셨다면\n",
    "\n",
    "```bash\n",
    "docker pull tensorflow/serving\n",
    "```\n",
    "을 WSL2 쉘에 실행시켜주세요 (맥북은 터미널에서도 가능합니다!)\n",
    "\n",
    "```bash\n",
    "docker run -p 8500:8500 \\\n",
    "\t\t\t-p 8501:8501 \\\n",
    "\t\t\t--mount type=bind, source=/tmp/models, target=/models/my_model\n",
    "\t\t\t-e MODEL_NAME=my_model \\\n",
    "\t\t\t-e MODEL_BASE_PATH=/models/my_model \\\n",
    "\t\t\t-t tensorflow/serving\n",
    "```\n",
    "\n",
    "그 다음 도커를 지정해주고 실행시켜 주세요\n",
    "\n",
    "해당 명령어의 경우 첫번째 줄은 기본 포트를 지정하는 것이며 2번째줄은 API 포트를 의미합니다. 3번째 줄은 모델 티렉토리를 마운트하는 것입니다. 4번째 줄은 모델 이름을 지정해주고 5번째 줄은 모델의 기본 경로를 의미합니다. 마지막 줄은 tensorflow/serving을 사용한다는 뜻입니다!\n",
    "\n",
    "만약 배포에 성공했다면 다음과 같은 그림이 나옵니다!\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/tfserving_result.max-800x600.png)\n",
    "\n",
    "[TFServing 결과물]\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/tflite.png)\n",
    "\n",
    "[TFLite 로고]\n",
    "\n",
    "### TFLite로 경량화 모델 만들기\n",
    "\n",
    "TFLite는 TensorFlow로 만들어진 모델을 휴대폰같은 기기에서도 실행될수 있게 더 작은 모델 크기로 변환해서 배포하는데 사용하게 만드는 방법입니다.\n",
    "TFLite의 경우 양자화라는 기법을 활용해 모델의 크기를 줄이지만 그렇다고 해서 모델의 성능이 크게 저하되지 않습니다.\\\n",
    "\n",
    "TFLite의 경우 TensorFlow에 내장되어 있어 별도의 설치가 없이 작동하는 방식입니다!\n",
    "\n",
    "그렇다면 tflite파일을 만들어보도록 하겠습니다! 첫번째로 아까 만들었던 모델을 불러옵니다!\n",
    "\n",
    "주의사항 현재 LMS에서 tflite모델이 만들어지긴 하지만 원인을 모르겠으나 모바일에서 tflite파일을 구동할때 중요한 '서명'이 지워진 상태로 나오고 있습니다. 그렇기에 실제 프로젝트를 진행할 때는 LMS에서 tflite파일을 만들기보다 Google Colab에서 만드는 것을 추천합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = os.getenv('HOME') + '/aiffel/mlops/best_model/model'\n",
    "best_model = tf.keras.models.load_model(load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델이 잘 불러왔는지 확인해보겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 이제 tflite파일로 변환을 진행해보도록 하겠습니다!\n",
    "\n",
    "변환을 진행할 떄에는 tf.lite.TFLiteConverter메소드를 활용하면 쉽게 바꿀 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tflite파일을 만들어서 우선 보관하도록 하겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tflite파일이 변환이 잘 되었는지 확인하기 위해 서명부분을 확인해보겠습니다!\n",
    "\n",
    "(위에서도 이야기했지만 현재 LMS에서는 서명이 이루어지지 않고 있습니다. 그렇기에 실제 실행되었을 때를 확인할 수 있도록 Colab파일을 제공하겠습니다)\n",
    "\n",
    "코랩파일(https://colab.research.google.com/drive/1Uhp4AOLUjvQWVFnsjoloVaSx-_TDJqzi?usp=sharing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "signatures = interpreter.get_signature_list()\n",
    "print(signatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 서명이 잘 작동하는지 확인하고 싶다면 아래 코드를 활용해주세요!\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/signatures.max-800x600.png)\n",
    "\n",
    "[실행이 잘 되었다면 아래와 같은 출력결과물이 나옵니다!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_lite = interpreter.get_signature_runner('serving_default')\n",
    "classify_lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/classifiy.max-800x600.png)\n",
    "\n",
    "[실행이 잘 되었다면 아래와 같은 출력결과물이 나옵니다!]\n",
    "\n",
    "이렇듯 우리는 Flutter나 Kotlin으로 안드로이드 앱을 만들어서 휴대폰에서도 구동할 수 있게 만들 수 있습니다.\\\n",
    "\n",
    "### 마치며\n",
    "\n",
    "이번 노드에서는 머신러닝을 실제 산업에서 운영했을 때 발생하는 문제들에 대해 배웠습니다.\n",
    "또한 MLOps 1단계부터 3단계까지 어떻게 나누어지는지 확인했으며 추가적으로 Data Driven AI에 대해서도 다루었습니다.\n",
    "MLOps에는 여러가지 툴이 있지만 이번에 간단하게 살펴본 툴은 TensorFlow Extended로 TensorFlow를 활용해서 모델을 엔드-투-엔드 모델 설계가 가능하다는 것을 배웠습니다.\n",
    "우리가 이번에 실습한 파트는 하이퍼 파라미터 튜닝을 할 수 있게 만드는 KerasTuner를 사용해서 최적의 모델을 만들어냈습니다.\n",
    "또한 해당 모델을 활용해 TFServing을 통해 API를 만들어냈으며 TFLite 모델로 변환해서 경량화모델을 만드는 것도 진행했습니다.\n",
    "\n",
    "이 노드를 공부한 사람들이면 느끼시겠지만\n",
    "이번 노드에서 실습한 내용은 MLOps의 거대한 강줄기중에 일부분에 불과합니다.\n",
    "그렇기에 여러분들이 MLOps를 더 이해하고 싶다면 프로젝트형 스터디를 기획해서 같이 공부하는 것도 좋다고 생각합니다!\n",
    "\n",
    "이번 노드를 통해 여러분들이 아이펠톤 프로젝트를 진행할 때 한결 수월해졌으면 좋겠습니다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
